# FaceBlit
### Real-Time Example-Based Stylization on Mobile Devices


Explore state-of-the-art in the field of style transfer based on guided texture synthesis, focus namely on methods which handle human faces [1] and can perform synthesis in real-time [2]. Implement selected method on a mobile device. Find the most suitable approach to detect facial landmarks possibly based on Convolutional Neural Network that would enable creation of semantically meaningful guidance for the synthesis. Implement a mobile application that transfers user specified artistic style to a photo or a video of a human face captured by built-in camera. Try to achieve interactive response on currently available mobile devices and discuss the trade-off between the stylization quality and the stylization speed.


[1] J. Fišer, O. Jamriška, D. Simons, E. Shechtman, J. Lu, P. Asente, M. Lukáč, and D. Sýkora: Example-Based Synthesis of Stylized Facial Animations. ACM Transactions on Graphics 36, 4 (2017). (SIGGRAPH, Los Angeles, USA, July 2017)


[2] D. Sýkora, O. Jamriška, O. Texler, J. Fišer, M. Lukáč, J. Lu, and E. Shechtman: StyleBlit: Fast Example-Based Stylization with Local Guidance. In Computer Graphics Forum. (Eurographics, Genova, Italy, May 2019)
